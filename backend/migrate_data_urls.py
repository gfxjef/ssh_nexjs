#!/usr/bin/env python3
"""
Script para migrar URLs en la base de datos al sistema centralizado de uploads.
NO mueve archivos f√≠sicos, solo actualiza las rutas en BD.
Los archivos se subir√°n nuevamente despu√©s.
"""

import sys
import os
import logging
from datetime import datetime

# A√±adir el directorio padre al path para poder importar m√≥dulos
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from db.mysql_connection import MySQLConnection

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class URLMigrator:
    """Clase para migrar URLs de la base de datos al sistema centralizado"""
    
    def __init__(self):
        self.db = MySQLConnection()
        self.migration_log = []
        
    def log_change(self, table, field, old_url, new_url, record_id):
        """Registra un cambio realizado"""
        change = {
            'timestamp': datetime.now().isoformat(),
            'table': table,
            'field': field,
            'id': record_id,
            'old_url': old_url,
            'new_url': new_url
        }
        self.migration_log.append(change)
        logger.info(f"‚úÖ {table}.{field} [ID:{record_id}]: {old_url} ‚Üí {new_url}")
    
    def migrate_posts_images(self):
        """Migra URLs de im√°genes en posts de bienestar"""
        logger.info("üîÑ Migrando URLs de im√°genes en posts...")
        
        # Obtener todos los posts con im√°genes
        query = """
        SELECT id, imagen_url, contenido 
        FROM posts_bienestar 
        WHERE imagen_url IS NOT NULL AND imagen_url != ''
        """
        
        posts = self.db.execute_query(query)
        if not posts:
            logger.info("üì≠ No se encontraron posts con im√°genes")
            return
        
        migrated_count = 0
        
        for post in posts:
            post_id = post['id']
            old_imagen_url = post['imagen_url']
            contenido = post['contenido']
            
            # Actualizar imagen_url principal (convertir a nueva estructura)
            new_imagen_url = self.convert_url_to_centralized(old_imagen_url, 'posts')
            
            if new_imagen_url != old_imagen_url:
                update_query = """
                UPDATE posts_bienestar 
                SET imagen_url = %s 
                WHERE id = %s
                """
                
                result = self.db.execute_query(update_query, (new_imagen_url, post_id), fetch=False)
                if result:
                    self.log_change('posts_bienestar', 'imagen_url', old_imagen_url, new_imagen_url, post_id)
                    migrated_count += 1
            
            # Actualizar URLs en el contenido HTML (im√°genes incrustadas)
            if contenido:
                new_contenido = self.update_content_urls(contenido, 'posts')
                if new_contenido != contenido:
                    update_content_query = """
                    UPDATE posts_bienestar 
                    SET contenido = %s 
                    WHERE id = %s
                    """
                    
                    result = self.db.execute_query(update_content_query, (new_contenido, post_id), fetch=False)
                    if result:
                        logger.info(f"‚úÖ Contenido actualizado para post ID:{post_id}")
        
        logger.info(f"‚úÖ Migraci√≥n de posts completada: {migrated_count} registros actualizados")
    
    def migrate_documents(self):
        """Migra URLs de documentos"""
        logger.info("üîÑ Migrando URLs de documentos...")
        
        # Obtener todos los documentos
        query = """
        SELECT id, ruta_archivo, nombre_archivo 
        FROM documentos 
        WHERE ruta_archivo IS NOT NULL AND ruta_archivo != ''
        """
        
        documentos = self.db.execute_query(query)
        if not documentos:
            logger.info("üì≠ No se encontraron documentos")
            return
        
        migrated_count = 0
        
        for doc in documentos:
            doc_id = doc['id']
            old_ruta = doc['ruta_archivo']
            
            # Convertir ruta a nueva estructura
            new_ruta = self.convert_url_to_centralized(old_ruta, 'documentos')
            
            if new_ruta != old_ruta:
                update_query = """
                UPDATE documentos 
                SET ruta_archivo = %s 
                WHERE id = %s
                """
                
                result = self.db.execute_query(update_query, (new_ruta, doc_id), fetch=False)
                if result:
                    self.log_change('documentos', 'ruta_archivo', old_ruta, new_ruta, doc_id)
                    migrated_count += 1
        
        logger.info(f"‚úÖ Migraci√≥n de documentos completada: {migrated_count} registros actualizados")
    
    def migrate_pdf_data(self):
        """Actualiza informaci√≥n de PDFs para nueva estructura"""
        logger.info("üîÑ Actualizando informaci√≥n de PDFs...")
        
        # Nota: Los PDFs se procesan din√°micamente, pero podr√≠amos tener metadatos en BD
        # Por ahora, solo registramos que esta migraci√≥n est√° lista
        logger.info("‚úÖ Migraci√≥n de PDFs preparada (se procesar√°n autom√°ticamente)")
    
    def convert_url_to_centralized(self, old_url, upload_type):
        """Convierte una URL antigua al formato centralizado"""
        if not old_url:
            return old_url
        
        # Si ya est√° en formato centralizado, no cambiar
        if f'/uploads/{upload_type}/' in old_url:
            return old_url
        
        # Extraer nombre del archivo de la URL antigua
        filename = os.path.basename(old_url)
        
        # Construir nueva URL centralizada
        new_url = f"/uploads/{upload_type}/{filename}"
        
        return new_url
    
    def update_content_urls(self, content, upload_type):
        """Actualiza URLs dentro del contenido HTML"""
        if not content:
            return content
        
        import re
        
        # Patrones para encontrar URLs de im√°genes en HTML
        patterns = [
            r'src="([^"]*/(uploads|backend/uploads)/[^"]*)"',
            r"src='([^']*/(uploads|backend/uploads)/[^']*)'",
            r'href="([^"]*/(uploads|backend/uploads)/[^"]*)"',
            r"href='([^']*/(uploads|backend/uploads)/[^']*)'",
        ]
        
        updated_content = content
        
        for pattern in patterns:
            matches = re.findall(pattern, updated_content)
            for match in matches:
                old_url = match[0] if isinstance(match, tuple) else match
                filename = os.path.basename(old_url)
                new_url = f"/uploads/{upload_type}/{filename}"
                
                updated_content = updated_content.replace(old_url, new_url)
        
        return updated_content
    
    def create_backup_script(self):
        """Crea un script de respaldo de las URLs originales"""
        backup_file = f"url_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.sql"
        
        backup_queries = [
            "-- Backup de URLs originales antes de migraci√≥n",
            f"-- Generado: {datetime.now().isoformat()}",
            "",
            "-- Posts",
            "CREATE TABLE IF NOT EXISTS posts_backup_urls AS",
            "SELECT id, imagen_url, contenido FROM posts_bienestar WHERE imagen_url IS NOT NULL;",
            "",
            "-- Documentos", 
            "CREATE TABLE IF NOT EXISTS documentos_backup_urls AS",
            "SELECT id, ruta_archivo FROM documentos WHERE ruta_archivo IS NOT NULL;",
        ]
        
        with open(backup_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(backup_queries))
        
        logger.info(f"üìù Script de backup creado: {backup_file}")
        return backup_file
    
    def generate_migration_report(self):
        """Genera un reporte de la migraci√≥n"""
        report_file = f"migration_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        import json
        
        report = {
            'migration_date': datetime.now().isoformat(),
            'total_changes': len(self.migration_log),
            'changes_by_table': {},
            'changes': self.migration_log
        }
        
        # Agrupar cambios por tabla
        for change in self.migration_log:
            table = change['table']
            if table not in report['changes_by_table']:
                report['changes_by_table'][table] = 0
            report['changes_by_table'][table] += 1
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"üìä Reporte de migraci√≥n generado: {report_file}")
        return report_file
    
    def run_migration(self):
        """Ejecuta la migraci√≥n completa"""
        logger.info("üöÄ Iniciando migraci√≥n de URLs a sistema centralizado")
        logger.info("‚ö†Ô∏è  NOTA: No se mueven archivos f√≠sicos, solo se actualizan URLs en BD")
        
        try:
            # Crear backup
            backup_file = self.create_backup_script()
            
            # Ejecutar migraciones
            self.migrate_posts_images()
            self.migrate_documents() 
            self.migrate_pdf_data()
            
            # Generar reporte
            report_file = self.generate_migration_report()
            
            logger.info("üéâ Migraci√≥n completada exitosamente")
            logger.info(f"üìù Backup: {backup_file}")
            logger.info(f"üìä Reporte: {report_file}")
            logger.info(f"üîÑ Total de cambios: {len(self.migration_log)}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error durante la migraci√≥n: {str(e)}")
            return False

def main():
    """Funci√≥n principal"""
    print("=" * 60)
    print("üîÑ MIGRACI√ìN DE URLs AL SISTEMA CENTRALIZADO")
    print("=" * 60)
    print("‚ö†Ô∏è  IMPORTANTE: Este script NO mueve archivos f√≠sicos")
    print("   Solo actualiza las URLs en la base de datos")
    print("   Los archivos se subir√°n nuevamente despu√©s")
    print("=" * 60)
    
    response = input("¬øContinuar con la migraci√≥n? (y/N): ")
    if response.lower() not in ['y', 'yes', 's√≠', 's']:
        print("‚ùå Migraci√≥n cancelada")
        return
    
    migrator = URLMigrator()
    success = migrator.run_migration()
    
    if success:
        print("\n‚úÖ Migraci√≥n completada exitosamente")
        print("üìù Archivos generados:")
        print("   - Script de backup SQL")
        print("   - Reporte de migraci√≥n JSON")
        print("\nüîÑ Pr√≥ximos pasos:")
        print("   1. Verificar que las URLs en BD apuntan al sistema centralizado")
        print("   2. Subir archivos nuevamente al directorio frontend/public/uploads/")
        print("   3. Probar endpoints de upload y descarga")
    else:
        print("\n‚ùå Error durante la migraci√≥n")
        print("   Revisar logs para m√°s detalles")

if __name__ == "__main__":
    main() 